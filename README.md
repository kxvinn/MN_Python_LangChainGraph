LangChain e LangGraph são ferramentas poderosas e muito úteis para a criação de aplicações baseadas em modelos de linguagem.

- **LangChain** facilita a interação com modelos de linguagem, permitindo a composição de fluxos de conversa complexos.
  
- **LangGraph** é uma extensão que permite estruturar essas interações em um grafo, facilitando a criação de workflows dinâmicos.

Neste documento, vou te explicar como instalar e executar projetos utilizando essas bibliotecas. 

---

## 1. Instalação
Antes de começar, é necessário instalar as dependências essenciais.


### 1.2 Instalar as Bibliotecas Necessárias
```sh
pip install langchain langgraph langchain-groq dotenv
```

Caso queira usar modelos específicos (como OpenAI, Groq, etc.), instale também:
```sh
pip install openai
```

---

## 2. Configuração de API Key
Para utilizar um provedor de IA, é necessário definir a chave de API. Crie um arquivo **api_key.env** no diretório do projeto e adicione:
```env
GROQ_API_KEY= "sua_chave_aqui"
```

No código, carregue essa chave:
```python
from dotenv import load_dotenv
import os

load_dotenv("api_key.env")
key = os.getenv("GROQ_API_KEY")
```

---

## 3. Criando um Projeto com LangGraph
Vamos construir um sistema simples onde um **receptor** recebe uma pergunta e a envia para um **professor virtual** para gerar uma resposta.

### 3.1 Importando Bibliotecas e Configurando o Modelo
```python
import os
import re
import json
from langchain.schema import SystemMessage, HumanMessage
from langchain_groq import ChatGroq
from langgraph.graph import StateGraph
from dotenv import load_dotenv

load_dotenv("api_key.env")
key = os.getenv("GROQ_API_KEY")

model = "mixtral-8x7b-32768"
chat = ChatGroq(model_name=model)
```

### 3.2 Criando os Nós do Grafo
```python
# Função para verificar se a pergunta é matemática
def check_question(question):
    pattern = r'[\d+\-*/=]'
    return bool(re.search(pattern, question))

# Nó receptor para validar e encaminhar perguntas
def receptor(state):
    question = state["question"]
    if not check_question(question):
        return {"error": "A pergunta não parece ser matemática."}
    return {"question": question, "category": "matemática"}

# Professor Virtual gera uma resposta
def virtual_teacher(state):
    question = state["question"]
    messages = [
        SystemMessage(content="Você é um professor de matemática. Explique cada solução claramente e passo a passo."),
        HumanMessage(content=question)
    ]
    response = chat.invoke(messages)
    return {"question": question, "category": "matemática", "response": response.content}
```

### 3.3 Criando e Configurando o Grafo
```python
# Nó final do grafo
def end_node(state):
    return state

# Criando o grafo
graph = StateGraph(dict)

graph.add_node("receptor", receptor)
graph.add_node("virtual_teacher", virtual_teacher)
graph.add_node("end", end_node)

graph.set_entry_point("receptor")

graph.add_edge("receptor", "virtual_teacher")
graph.add_edge("virtual_teacher", "end")
```

### 3.4 Executando o Grafo
```python
teacher = graph.compile()
question = "Como resolver a equação 2x + 3 = 7?"
response = teacher.invoke({"question": question})

# Exibindo a resposta
print(json.dumps(response, indent=2, ensure_ascii=False))
```

---

## 4. Estrutura do Projeto
Um projeto LangChain e LangGraph pode ser estruturado assim:
```
meu_projeto/
│── api_key.env  # Chave de API
│── main.py      # Código principal
│── requirements.txt  # Dependências
└── README.md    # Documentação
```

---

## 5. Testando e Executando o Projeto
### 5.1 Rodando o Script

```sh
python main.py
```

Se configurado corretamente, você verá a resposta da IA para a pergunta matemática.




---

## 6. Conclusão
Agora você tem um projeto funcional utilizando LangChain e LangGraph. Esse exemplo mostra como estruturar fluxos de conversa com IA e organizar o processamento usando grafos.

Caso tenha dúvidas, confira a [documentação oficial](https://python.langchain.com/) para LangChain e [LangGraph](https://github.com/langchain-ai/langgraph).

